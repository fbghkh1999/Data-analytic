{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gym.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPa+ItyO8LNnBuGAkQEIBhI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbghkh1999/dataIntroduction/blob/main/gym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAoCkZfXkAv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "19f984d4-588e-4452-fef3-d3dc04a1a953"
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ-rgzrdkHnY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b7e4072b-9b5a-447d-d787-92c85a512189"
      },
      "source": [
        "pip install gym "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VZaQB39kVsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "af44dc59-27f0-46b7-fe45-2e496fd58e80"
      },
      "source": [
        "pip install keras-rl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-rl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/87/4b57eff8e4bd834cea0a75cd6c58198c9e42be29b600db9c14fafa72ec07/keras-rl-0.4.2.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from keras-rl) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.7->keras-rl) (1.15.0)\n",
            "Building wheels for collected packages: keras-rl\n",
            "  Building wheel for keras-rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-rl: filename=keras_rl-0.4.2-cp36-none-any.whl size=48380 sha256=c07bbf3051cbfc042c1596f735966e630baefd421d9df3a0cc4853377b09a628\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/4d/84/9254c9f2e8f51865cb0dac8e79da85330c735551d31f73c894\n",
            "Successfully built keras-rl\n",
            "Installing collected packages: keras-rl\n",
            "Successfully installed keras-rl-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmn4ejPnG_Ch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d21db7a5-4397-4f37-a9b3-aaf8afe44c34"
      },
      "source": [
        "pip install git+git://github.com/wau/keras-rl2.git --upgrade --no-deps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/wau/keras-rl2.git\n",
            "  Cloning git://github.com/wau/keras-rl2.git to /tmp/pip-req-build-zd95sm4e\n",
            "  Running command git clone -q git://github.com/wau/keras-rl2.git /tmp/pip-req-build-zd95sm4e\n",
            "Building wheels for collected packages: keras-rl2\n",
            "  Building wheel for keras-rl2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-rl2: filename=keras_rl2-1.0.4-cp36-none-any.whl size=53199 sha256=f4fa0ecbf0f11846d78a28faf4a82e2aa89399162e269a6e9ea1393038a25313\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3eqxgpdn/wheels/2b/a2/35/5c5d276e34f74ea063a6f2498e9b4a059027fa9da74c7fd6a3\n",
            "Successfully built keras-rl2\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbZSpgQzkLcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "b095a7fe-2655-46a0-901f-e1d3422710cb"
      },
      "source": [
        "'''import gym\n",
        "env = gym.make('CartPole-v0')\n",
        "env.reset()\n",
        "for _ in range(1000):\n",
        "    env.render()\n",
        "    env.step(env.action_space.sample()) # take a random action\n",
        "env.close()'''\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "import random\n",
        "from keras.models     import Sequential\n",
        "from keras.layers     import Dense\n",
        "from keras.optimizers import Adam\n",
        "ENV_NAME = 'MountainCar-v0'\n",
        "\n",
        "# Get the environment and extract the number of actions available in the Cartpole problem\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "env.reset()\n",
        "goal_steps = 200\n",
        "score_requirement = -198\n",
        "intial_games = 10000\n",
        "\n",
        "\n",
        "\n",
        "def model_data_preparation():\n",
        "    training_data = []\n",
        "    accepted_scores = []\n",
        "    for game_index in range(intial_games):\n",
        "        score = 0\n",
        "        game_memory = []\n",
        "        previous_observation = []\n",
        "        for step_index in range(goal_steps):\n",
        "            action = random.randrange(0, 3)\n",
        "            observation, reward, done, info = env.step(action)\n",
        "            \n",
        "            if len(previous_observation) > 0:\n",
        "                game_memory.append([previous_observation, action])\n",
        "                \n",
        "            previous_observation = observation\n",
        "            if observation[0] > -0.2:\n",
        "                reward = 1\n",
        "            \n",
        "            score += reward\n",
        "            if done:\n",
        "                break\n",
        "            \n",
        "        if score >= score_requirement:\n",
        "            accepted_scores.append(score)\n",
        "            for data in game_memory:\n",
        "                if data[1] == 1:\n",
        "                    output = [0, 1, 0]\n",
        "                elif data[1] == 0:\n",
        "                    output = [1, 0, 0]\n",
        "                elif data[1] == 2:\n",
        "                    output = [0, 0, 1]\n",
        "                training_data.append([data[0], output])\n",
        "        \n",
        "        env.reset()\n",
        "    \n",
        "    print(accepted_scores)\n",
        "    return training_data\n",
        "\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "\n",
        "def build_model(input_size, output_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_size, activation='relu'))\n",
        "    model.add(Dense(52, activation='relu'))\n",
        "    model.add(Dense(output_size, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=Adam())\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def train_model(training_data):\n",
        "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
        "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
        "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
        "    \n",
        "    model.fit(X, y, epochs=5)\n",
        "    return model\n",
        "train=model_data_preparation()\n",
        "trained_model = train_model(train)\n",
        "'''\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
        "model.add(Dense(16))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))'''\n",
        "#print(trai.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-186.0, -196.0, -178.0, -176.0, -186.0, -174.0, -184.0, -198.0, -176.0, -178.0, -182.0, -174.0, -178.0, -190.0, -180.0, -184.0, -176.0, -168.0, -174.0, -188.0, -174.0, -194.0, -192.0, -176.0, -192.0, -178.0, -176.0, -176.0, -192.0, -172.0, -186.0, -168.0, -176.0, -184.0, -190.0, -188.0, -194.0, -176.0, -196.0, -170.0, -190.0, -170.0]\n",
            "Train on 8358 samples\n",
            "Epoch 1/5\n",
            "8358/8358 [==============================] - 0s 33us/sample - loss: 0.2274\n",
            "Epoch 2/5\n",
            "8358/8358 [==============================] - 0s 35us/sample - loss: 0.2218\n",
            "Epoch 3/5\n",
            "8358/8358 [==============================] - 0s 33us/sample - loss: 0.2208\n",
            "Epoch 4/5\n",
            "8358/8358 [==============================] - 0s 31us/sample - loss: 0.2200\n",
            "Epoch 5/5\n",
            "8358/8358 [==============================] - 0s 33us/sample - loss: 0.2197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nmodel = Sequential()\\nmodel.add(Flatten(input_shape=(1,) + env.observation_space.shape))\\nmodel.add(Dense(16))\\nmodel.add(Activation('relu'))\\nmodel.add(Dense(nb_actions))\\nmodel.add(Activation('linear'))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNNG9hmundIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "a548f426-bfd8-485a-f8cf-afbbd3570e62"
      },
      "source": [
        "'''policy = EpsGreedyQPolicy()\n",
        "memory = SequentialMemory(limit=50000, window_length=1)\n",
        "dqn = DQNAgent(model=trained_model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,target_model_update=1e-2, policy=policy)\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "# Okay, now it's time to learn something! We visualize the training here for show, but this slows down training quite a lot. \n",
        "dqn.fit(env, nb_steps=5000, visualize=False, verbose=2)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"policy = EpsGreedyQPolicy()\\nmemory = SequentialMemory(limit=50000, window_length=1)\\ndqn = DQNAgent(model=trained_model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,target_model_update=1e-2, policy=policy)\\ndqn.compile(Adam(lr=1e-3), metrics=['mae'])\\n# Okay, now it's time to learn something! We visualize the training here for show, but this slows down training quite a lot. \\ndqn.fit(env, nb_steps=5000, visualize=False, verbose=2)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1r7wS-BILNh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2c2a7a6-ffe4-4d26-e138-e4b7c036b302"
      },
      "source": [
        "env.seed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Wrapper.seed of <TimeLimit<MountainCarEnv<MountainCar-v0>>>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D20DclXErNl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}